# On AI

While this mono repository was initaly created before the AI craze it was heavily pushed in VS-Code and VS in general. It was much easier to use it than to disable it by default. At first it was really a nuisance gray auto suggestion text popping up left and right. But after improvements in LLM models their coding abilites were at a stage where i felt that not using it results in a sever disadvantage. I saw so many people turning their ideas into apps that actually worked.

While I was fixing bugs left and right. My programming abilities and experience was limited to 2-3 years while LLMs already absorbed the knowledge of the past 50 years. While I needed to learn a new language it already understood it well enough to write moderately complex apps. Where I was struggling with the build system.

So I started using it more and more. Did it speed up my iteration speed? YES it did. My idea was being so fast implemented I could tweak problems with the idea much faster. The true value of an idea lies in its implementation not in the idea itself. But overtime i felt as if LLMs took over too much. It felt like I would lose the grasp of the idea itself.

While its true that the idea of something is decoupled from its implementation in the sense that an idea does not need an implementation, the implementation needs an idea to exist in the first place. Even if its only a vague idea.

## The tranformation of the idea

An implementation has the ability to transform an idea, it could expand or contract it. Imagine an idea of an crossplatform app for various platforms. The implementation could add a feature that wont work on phones. What does that have to do with LLMs? It does not matter of sophisticated a LLMs it could even be much more "smarter" than now it could never have the same idea in his "thoughts"/context window than you have in yours. This has something to do with words, meaning and context. Saying: "I want a app that works on windows and linux" and thinking and yea have the ability to easily add new platforms if I want to.

## Lost in translation

An LLM will never know your thoughts. And you might think: "duuuh, of course, it cant read your mind! You have to be more specific!". The thing is humans have much much implicit behavior and meaning in speech and behavior in general, that you might think. Having an idea in your head and not the correct ability to translate it to speech does not make the idea less valuable. BUT! translating something in speech/words/language is always a lossy operation, even if you dont believe that. We will lose context/meaning and even ideas itself. Saying: "I want that the app works". Can mean so many things in so many different contexts.

You can see the lose directly using code refactoring with an LLM it always add concepts and ideas to your code you didnt think of and didnt use initally in the code base. Using 5 different ideas and ways to solve a problem it much worse than using 1 way to solve similar problems. In C# I personally prefer to use LINQ where I can that does not mean the LLM will do it. The number of thinks in my head that I dont think consciously about that influence the way I code. Would be too much to tell the LLM. And also I would miss important aspects.

When "talking" to an LLM it always means losing something. And I think I lost already too much.

## Losing too much

Using LLMs I lost understanding of my own code. Using LLMs I lost meaning in my ideas I wanted to implemented because I thought a working idea is more important. Slowly but surely losing the idea itself in the process.
I also think I lost valuable learning experiences.

## So never use an LLM?

NO, this is not the conclusion to take. The main conclusion is that it should not generate code what so ever. It pollutes the implementation way to much. I found that LLMs are sometimes much better than an online search. Or for translating code to another language.
